{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GENERATING IMAGES, QUESTIONS AND ANSWERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import radians, cos\n",
    "import cv2\n",
    "\n",
    "class SortOfCLEVRGenerator(object):\n",
    "    colors = [\n",
    "        (0,0,255),      #red\n",
    "        (255,0,0),      #blue\n",
    "        (0,255,0),      #green\n",
    "        (0,156,255),    #orange\n",
    "        (0,255,255),    #yellow\n",
    "        (128,128,128)   #grey\n",
    "    ]\n",
    "    shapes = [\n",
    "        's',    #square\n",
    "        'c',    #circle\n",
    "    ]\n",
    "\n",
    "    img_size = 75\n",
    "    shape_size = 10\n",
    "\n",
    "    question_vector_size = 11\n",
    "    answer_vector_size = 10\n",
    "\n",
    "    def __init__(self, number_questions=10, number_shapes=6):\n",
    "        self.number_questions = number_questions\n",
    "        self.number_shapes = number_shapes\n",
    "\n",
    "    def generate_centers(self):\n",
    "        centers = []\n",
    "        for n in range(self.number_shapes):\n",
    "            collision = True\n",
    "            while collision:\n",
    "                center = np.random.randint(self.shape_size, self.img_size - self.shape_size, 2)\n",
    "                collision = False\n",
    "                for c in centers:\n",
    "                    if ((center-c)**2).sum() < (self.shape_size)**2:\n",
    "                        collision = True\n",
    "            centers.append(center)\n",
    "        return centers\n",
    "\n",
    "    def generate_sample(self):\n",
    "        centers = self.generate_centers()\n",
    "        shape_choice = np.random.randint(2, size=self.number_shapes)\n",
    "        img = np.zeros((self.img_size,self.img_size,3))\n",
    "        representation = []\n",
    "        for idx, c in enumerate(centers):\n",
    "            shape = self.shapes[shape_choice[idx]]\n",
    "            if shape == 's':\n",
    "                const = int(self.shape_size * cos(radians(45))/2)\n",
    "                start = (c[0]-const, c[1]-const)\n",
    "                end = (c[0]+const, c[1]+const)\n",
    "                img = cv2.rectangle(img, start, end, self.colors[idx], -1)\n",
    "            else:\n",
    "                img = cv2.circle(img, (c[0], c[1]), int(self.shape_size/2), self.colors[idx], -1)\n",
    "            representation.append([c, shape])\n",
    "        return img, representation\n",
    "\n",
    "    def generate_questions(self, representation, number_questions=10):\n",
    "        # [red, blue, green, orange, yellow, gray, relational, non-relational, question 1, question 2, question 3]\n",
    "        questions = []\n",
    "        for q in range(number_questions):\n",
    "            for r in range(2):\n",
    "                question = [0] * self.question_vector_size\n",
    "                color = np.random.randint(6)\n",
    "                question[color] = 1\n",
    "                question[6 + r] = 1\n",
    "                question_type = np.random.randint(3)\n",
    "                question[8 + question_type] = 1\n",
    "                questions.append(question)\n",
    "        return questions\n",
    "\n",
    "    def generate_answers(self, representation, questions):\n",
    "        #[yes, no, square, circle, 1, 2, 3, 4, 5, 6]\n",
    "        answers = []\n",
    "        for question in questions:\n",
    "            answer = [0] * self.answer_vector_size\n",
    "            color = question[:6].index(1)\n",
    "            if question[6]:\n",
    "                if question[8]: #The shape of the nearest object?\n",
    "                    dist = [((representation[color][0]-obj[0])**2).sum() for obj in representation]\n",
    "                    dist[dist.index(0)] = float('inf')\n",
    "                    closest = dist.index(min(dist))\n",
    "                    if representation[closest][1] == 's':\n",
    "                        answer[2] = 1\n",
    "                    else:\n",
    "                        answer[3] = 1\n",
    "                elif question[9]: #The shape of the farthest object?\n",
    "                    dist = [((representation[color][0]-obj[0])**2).sum() for obj in representation]\n",
    "                    furthest = dist.index(max(dist))\n",
    "                    if representation[furthest][1] == 's':\n",
    "                        answer[2] = 1\n",
    "                    else:\n",
    "                        answer[3] = 1\n",
    "\n",
    "                else: #How many objects have the same shape?\n",
    "                    count = -1\n",
    "                    shape = representation[color][1]\n",
    "                    for obj in representation:\n",
    "                        if obj[1] == shape:\n",
    "                            count += 1\n",
    "                    answer[count + 4] = 1\n",
    "            else:\n",
    "                if question[8]: #Is it a circle or a rectangle?\n",
    "                    if representation[color][1] == 's':\n",
    "                        answer[2] = 1\n",
    "                    else:\n",
    "                        answer[3] = 1\n",
    "                elif question[9]: #Is it on the bottom of the image?\n",
    "                    if representation[color][0][1] > self.img_size/2:\n",
    "                        answer[0] = 1\n",
    "                    else:\n",
    "                        answer[1] = 1\n",
    "                else: #Is it on the left of the image?\n",
    "                    if representation[color][0][0] > self.img_size/2:\n",
    "                        answer[1] = 1\n",
    "                    else:\n",
    "                        answer[0] = 1\n",
    "            answers.append(answer)\n",
    "        return answers\n",
    "\n",
    "    def generate_dataset(self):\n",
    "        img, representation = self.generate_sample()\n",
    "        questions = self.generate_questions(representation)\n",
    "        answers = self.generate_answers(representation, questions)\n",
    "        dataset = (img.astype('float32'), questions, answers)\n",
    "        return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Sort-of-CLEVR Training Dataset: 100%|██████████| 9800/9800 [00:04<00:00, 1962.15it/s]\n",
      "Generating Sort-of-CLEVR Test Dataset: 100%|██████████| 200/200 [00:00<00:00, 1195.05it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = []\n",
    "train_dataset = []\n",
    "test_size = 200 #200\n",
    "train_size = 9800 #9800\n",
    "\n",
    "\n",
    "generator = SortOfCLEVRGenerator()\n",
    "\n",
    "for i in tqdm(range(train_size), desc='Generating Sort-of-CLEVR Training Dataset'):\n",
    "        dataset = generator.generate_dataset()\n",
    "        train_dataset.append(dataset)\n",
    "\n",
    "for i in tqdm(range(test_size), desc='Generating Sort-of-CLEVR Test Dataset'):\n",
    "        dataset = generator.generate_dataset()\n",
    "        test_dataset.append(dataset)\n",
    "        \n",
    "with open(\"sort-of-clevr.p\", 'wb') as f:\n",
    "    pickle.dump((train_dataset, test_dataset), f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_img = []\n",
    "train_q = []\n",
    "train_a = []\n",
    "for img, questions, answers in test_dataset:\n",
    "    img_train = img/255\n",
    "    for q, a in zip(questions, answers):\n",
    "        train_img += [img_train]\n",
    "        train_q += [q]\n",
    "        train_a += [a]\n",
    "train_img = np.stack(train_img)\n",
    "train_q = np.vstack(train_q)\n",
    "train_a = np.vstack(train_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_img))\n",
    "print(len(train_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, questions, answers = generator.generate_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to translate Question and Answer into string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_img(img):\n",
    "    img = np.fliplr(img.reshape(-1,3)).reshape(img.shape)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "def translate_question(q):\n",
    "    if len(q) != 11:\n",
    "        return 'Not a proper question'\n",
    "    colors = ['red', 'blue', 'green', 'orange', 'yellow', 'gray']\n",
    "    idx= np.argwhere(q[:6])[0][0]\n",
    "    color = colors[idx]\n",
    "    if q[6]:\n",
    "        if q[8]:\n",
    "            return 'The shape of the nearest object to the object in ' + color + ' is?' \n",
    "        elif q[9]:\n",
    "            return 'The shape of the farthest object away from the object in ' + color + ' is?'\n",
    "        elif q[10]:\n",
    "            return 'How many objects have the same shape as the object in ' + color + '?'\n",
    "    else:\n",
    "        if q[8]:\n",
    "            return 'Is the object in color ' + color + ' a circle or a rectangle?'\n",
    "        elif q[9]:\n",
    "            return 'Is the object in color ' + color + ' on the bottom of the image?'\n",
    "        elif q[10]:\n",
    "            return 'Is the object in color ' + color + ' on the left of the image?'\n",
    "        \n",
    "def translate_answer(a):\n",
    "    if len(a) != 10:\n",
    "        return 'Not a proper answer'\n",
    "    if a[0]:\n",
    "        return 'yes'\n",
    "    if a[1]:\n",
    "        return 'no'\n",
    "    if a[2]:\n",
    "        return 'rectangle'\n",
    "    if a[3]:\n",
    "        return 'circle'\n",
    "    return np.argwhere(a[4:])[0][0] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 75, 3)\n",
      "Is the object in color red on the bottom of the image?\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "idx = 20\n",
    "idb = 7\n",
    "img, q, a = train_dataset[idx]\n",
    "print(len(train_dataset[idx][2][1]))\n",
    "visualize_img(img/255)\n",
    "print (img.shape)\n",
    "print (translate_question(q[idb]))\n",
    "print (translate_answer(a[idb]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Feature Maps Post-process to Relation Network Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import BatchNormalization\n",
    "def ConvolutionNetworks(kernel_size=3, stride_size=2):\n",
    "    def conv(model):\n",
    "        model = Conv2D(24, (5, 5), strides=(stride_size, stride_size),activation='relu',input_shape=(75, 75, 3), data_format='channels_last')(model)\n",
    "        model = BatchNormalization()(model)\n",
    "        model = Conv2D(24, (5, 5), strides=(stride_size, stride_size),activation='relu')(model)\n",
    "        model = BatchNormalization()(model)\n",
    "        model = Conv2D(24, (kernel_size, kernel_size), strides=(stride_size, stride_size),activation='relu')(model)\n",
    "        model = BatchNormalization()(model)\n",
    "        model = Conv2D(24, (3, 3), strides=(1, 1),activation='relu')(model)\n",
    "        model = BatchNormalization()(model)\n",
    "        return model\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Lambda, Concatenate, Add\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for  different layers (Eg. MLP , G_THETA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "def g_th(layers):\n",
    "    def f(model):\n",
    "        for n in range(len(layers)):\n",
    "            model = layers[n](model)\n",
    "        return model\n",
    "    return f\n",
    "\n",
    "def stack_layer(layers):\n",
    "    def f(x):\n",
    "        for k in range(len(layers)):\n",
    "            x = layers[k](x)\n",
    "        return x\n",
    "    return f\n",
    "\n",
    "def g_theta(h_unit=256, layers=4):\n",
    "    r = []\n",
    "    for k in range(layers):\n",
    "        r.append(Dense(h_unit))\n",
    "        r.append(Activation('relu'))\n",
    "    return g_th(r)\n",
    "\n",
    "def get_MLP():\n",
    "    return g_th()\n",
    "\n",
    "def RelationNetworks(objects, question):\n",
    "    g_t = g_theta()\n",
    "    relations = compute_relations(objects,question)\n",
    "    g_all = []\n",
    "    for i, r in enumerate(relations):\n",
    "        g_all.append(g_t(r))\n",
    "    combined_relation = Add()(g_all)\n",
    "    f_out = f_theta()(combined_relation)\n",
    "    return f_out\n",
    "\n",
    "def build_tag(conv):\n",
    "    d = K.int_shape(conv)[2]\n",
    "    tag = np.zeros((d,d,2))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            tag[i,j,0] = float(int(i%d))/(d-1)*2-1\n",
    "            tag[i,j,1] = float(int(j%d))/(d-1)*2-1\n",
    "    tag = K.variable(tag)\n",
    "    tag = K.expand_dims(tag, axis=0)\n",
    "    batch_size = K.shape(conv)[0]\n",
    "    tag = K.tile(tag, [batch_size,1,1,1])\n",
    "    return Input(tensor=tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definning Visual Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_scene = Input((75, 75, 3))\n",
    "visual_question = Input((11,))\n",
    "visual_conv = ConvolutionNetworks()(visual_scene)\n",
    "tag = build_tag(visual_conv)\n",
    "visual_conv = Concatenate()([tag, visual_conv])\n",
    "visual_RN = RelationNetworks(visual_conv, visual_question)\n",
    "visual_out = Dense(10, activation='softmax')(visual_RN)\n",
    "VisualModel = Model(inputs=[visual_scene, visual_question, tag], outputs=visual_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DataGenerator(object):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, training_set, test_set, is_baseline, dim_x = 75, dim_y = 75, channel = 3, q_dim = 11, a_dim = 10, batch_size = 64, shuffle = True):\n",
    "        'Initialization'\n",
    "        self.dim_x = dim_x\n",
    "        self.dim_y = dim_y\n",
    "        self.channel = channel\n",
    "        self.q_dim = q_dim\n",
    "        self.a_dim = a_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.training_set = training_set\n",
    "        self.test_set = test_set\n",
    "        self.is_baseline = is_baseline\n",
    "\n",
    "    def generate_training(self):\n",
    "        'Generates batches of samples'\n",
    "        # Infinite loop\n",
    "        while 1:\n",
    "            # Generate order of exploration of dataset\n",
    "            \n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(self.training_set)\n",
    "\n",
    "            # Generate batches\n",
    "            data_size = len(self.training_set)\n",
    "            imax = int(data_size/self.batch_size)\n",
    "            for i in range(imax):\n",
    "                # Generate data\n",
    "                imgs, questions, answers = self.__data_generation(self.training_set[i: i + self.batch_size])\n",
    "                imgs, questions, answers = self.randomize(imgs, questions, answers)\n",
    "                yield [imgs, questions], answers\n",
    "                \n",
    "    def generate_test(self):\n",
    "        'Generates batches of samples'\n",
    "        # Infinite loop\n",
    "        while 1:\n",
    "            # Generate order of exploration of dataset\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(self.test_set)\n",
    "\n",
    "            # Generate batches\n",
    "            data_size = len(self.test_set)\n",
    "            imax = int(data_size/self.batch_size)\n",
    "            for i in range(imax):\n",
    "                # Generate data\n",
    "                imgs, questions, answers = self.__data_generation(self.test_set[i: i+self.batch_size])\n",
    "                imgs, questions, answers = self.randomize(imgs, questions, answers)\n",
    "                yield [imgs, questions], answers\n",
    "    \n",
    "    def randomize(self, a, b, c):\n",
    "        # Generate the permutation index array.\n",
    "        permutation = np.random.permutation(a.shape[0])\n",
    "        # Shuffle the arrays by giving the permutation in the square brackets.\n",
    "        shuffled_a = a[permutation]\n",
    "        shuffled_b = b[permutation]\n",
    "        shuffled_c = c[permutation]\n",
    "        return shuffled_a, shuffled_b, shuffled_c\n",
    "\n",
    "    def __data_generation(self, dataset):\n",
    "        'Generates data of batch_size samples' # X : (n_samples, v_size, v_size, v_size, n_channels)\n",
    "        # Initialization\n",
    "        q_lenght = len(dataset[0][1])\n",
    "        imgs = np.empty((self.batch_size*q_lenght, self.dim_x, self.dim_y, self.channel))\n",
    "        questions = np.empty((self.batch_size*q_lenght, self.q_dim), dtype = int)\n",
    "        answers = np.empty((self.batch_size*q_lenght, self.a_dim), dtype = int)\n",
    "        c = 0\n",
    "        for img, question, answer in dataset:\n",
    "            img = img/255\n",
    "            for q, a in zip(question, answer):\n",
    "                imgs[c, :, :, :]  = img\n",
    "                questions[c, :] = q\n",
    "                answers[c, :] = a\n",
    "                c += 1\n",
    "        return imgs, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "lr = 1e-4\n",
    "adam = Adam(lr=lr)\n",
    "VisualModel.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "data_generator = DataGenerator(train_dataset, test_dataset, False, batch_size=batch_size)\n",
    "training_generator = data_generator.generate_training()\n",
    "validation_generator = data_generator.generate_test()\n",
    "visualmodel_history = VisualModel.fit_generator(generator = training_generator,\n",
    "                    steps_per_epoch = (len(train_dataset))//batch_size,\n",
    "                    validation_data = validation_generator,\n",
    "                    validation_steps = (len(test_dataset))//batch_size,\n",
    "                    epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "VisualModel.load_weights('Model/VisualModelLarge5.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_set(dataset_size):\n",
    "    generator = SortOfCLEVRGenerator()\n",
    "    testset = []\n",
    "    rel_testset = []\n",
    "    norel_testset = []\n",
    "    norel_ids = []\n",
    "    rel_ids = []\n",
    "\n",
    "    for i in range(dataset_size):\n",
    "        imgs, questions, answers = generator.generate_dataset()\n",
    "        testset.append((imgs, questions, answers))\n",
    "        norel_questions = []\n",
    "        rel_questions = []\n",
    "        norel_answers = []\n",
    "        rel_answers = []\n",
    "        for q_idx in range(len(questions)):\n",
    "            if questions[q_idx][6] == 1:\n",
    "                rel_questions.append(questions[q_idx])\n",
    "                rel_answers.append(answers[q_idx]) \n",
    "            else:\n",
    "                norel_questions.append(questions[q_idx])\n",
    "                norel_answers.append(answers[q_idx]) \n",
    "        norel_testset.append((imgs, norel_questions, norel_answers))\n",
    "        rel_testset.append((imgs, rel_questions, rel_answers))\n",
    "    return rel_testset, norel_testset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    rel, norel, test = create_test_set(200)\n",
    "    batch_size = 1\n",
    "    rel_generator = DataGenerator(None, rel, False, batch_size=batch_size)\n",
    "    norel_generator = DataGenerator(None, norel, False, batch_size=batch_size)\n",
    "    test_generator = DataGenerator(None, test, False, batch_size=batch_size)\n",
    "    r_generator = rel_generator.generate_test()\n",
    "    res_rel = model.evaluate_generator(r_generator, steps=len(rel)//batch_size, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "    nr_generator = norel_generator.generate_test()\n",
    "    res_norel = model.evaluate_generator(nr_generator, steps=len(rel)//batch_size, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "    re_generator = test_generator.generate_test()\n",
    "    res = model.evaluate_generator(re_generator, steps=len(rel)//batch_size, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "    print(res_rel)\n",
    "    print(res_norel)\n",
    "    print(res)\n",
    "    return res_rel[1], res_norel[1], res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5895933140032412, 0.8399999974668027]\n",
      "[0.12473873559606993, 0.969999997317791]\n",
      "[0.35716602137341397, 0.9049999949336052]\n"
     ]
    }
   ],
   "source": [
    "res = test_model(VisualModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accracy of Relational Question is 0.837000, The accuracy of Non-Relational Question is 0.968000, Overall Accuracy is 0.902500\n"
     ]
    }
   ],
   "source": [
    "print ('The accracy of Relational Question is %f, The accuracy of Non-Relational Question is %f, Overall Accuracy is %f' %res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(a, num_classes): \n",
    "    return np.squeeze(np.eye(num_classes)[a.reshape(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 1 0 1 0 0 1 0]]\n",
      "Question:  The shape of the farthest object away from the object in yellow is?\n",
      "Predicted answer: rectangle\n",
      "Actual answer: rectangle\n"
     ]
    }
   ],
   "source": [
    "#### Test image\n",
    "idx = 25\n",
    "idb = 16\n",
    "img, q, a = test_dataset[idx]\n",
    "img1 = img/255\n",
    "visualize_img(img1)\n",
    "act_ans = translate_answer(a[idb])\n",
    "#print(a[idb])\n",
    "\n",
    "ques = translate_question(q[idb])\n",
    "test_img = np.reshape(img1,(1,75,75,3))\n",
    "test_q = np.reshape(q[idb],(1,11))\n",
    "# print(test_q)\n",
    "#t = np.array([img,np.array(q[4])])\n",
    "### predict answer\n",
    "\n",
    "print(test_q)\n",
    "\n",
    "data1 = []\n",
    "data1.append(test_img)\n",
    "data1.append(test_q)\n",
    "test_a = VisualModel.predict(data1)\n",
    "# print(test_q)\n",
    "#print(test_a[0])\n",
    "test_ans=one_hot(np.array(np.argmax(test_a[0])),10)\n",
    "test_ans = translate_answer(test_ans)\n",
    "\n",
    "print(\"Question: \",ques)\n",
    "print(\"Predicted answer:\",test_ans)\n",
    "print(\"Actual answer:\",act_ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing questions and testing for random question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]\n",
      "The shape of the nearest object to the object in yellow is?\n",
      "[0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0]\n",
      "Is the object in color yellow on the bottom of the image?\n",
      "[0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0]\n",
      "The shape of the farthest object away from the object in yellow is?\n",
      "[0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0]\n",
      "Is the object in color orange on the bottom of the image?\n",
      "[0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0]\n",
      "The shape of the farthest object away from the object in orange is?\n",
      "[0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0]\n",
      "Is the object in color orange a circle or a rectangle?\n",
      "[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1]\n",
      "How many objects have the same shape as the object in gray?\n",
      "[0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0]\n",
      "Is the object in color orange on the bottom of the image?\n",
      "[0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0]\n",
      "The shape of the nearest object to the object in green is?\n",
      "[0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0]\n",
      "Is the object in color gray on the bottom of the image?\n",
      "[1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]\n",
      "The shape of the farthest object away from the object in red is?\n",
      "[0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1]\n",
      "Is the object in color blue on the left of the image?\n",
      "[0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n",
      "The shape of the nearest object to the object in blue is?\n",
      "[0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n",
      "Is the object in color yellow on the left of the image?\n",
      "[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]\n",
      "The shape of the nearest object to the object in yellow is?\n",
      "[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1]\n",
      "Is the object in color orange on the left of the image?\n",
      "[0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
      "The shape of the nearest object to the object in gray is?\n",
      "[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1]\n",
      "Is the object in color green on the left of the image?\n",
      "[0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "The shape of the nearest object to the object in orange is?\n",
      "[0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1]\n",
      "Is the object in color blue on the left of the image?\n"
     ]
    }
   ],
   "source": [
    "for ques in test_dataset[1][1]:\n",
    "    print(ques)\n",
    "    print(translate_question(ques))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = [0,0,0,1,0,0,1,0,0,1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "im,_,_ = test_dataset[1]\n",
    "im = im/255\n",
    "test_img = np.reshape(im,(1,75,75,3))\n",
    "test_q = np.reshape(q,(1,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_a = VisualModel.predict([test_img,test_q])\n",
    "test_ans=one_hot(np.array(np.argmax(test_a[0])),10)\n",
    "test_ans = translate_answer(test_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rectangle\n"
     ]
    }
   ],
   "source": [
    "print(test_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
